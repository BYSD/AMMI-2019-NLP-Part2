{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyunghyuncho/ammi-2019-nlp/blob/master/01-day-LM/ken_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVGBphEakB1c"
   },
   "source": [
    "# KenLM Framework for Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mu9NmEikGja"
   },
   "source": [
    "## Install KenLM\n",
    "\n",
    "### Reference: https://github.com/kpu/kenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/kpu/kenlm/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "90dlx6MzkrRB",
    "outputId": "6d2e42e5-3675-4d87-b79a-ff562b9e4c27"
   },
   "outputs": [],
   "source": [
    "import kenlm\n",
    "import os\n",
    "import re\n",
    "import utils.ngram_utils as ngram_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66787a1290f64fd0b116b0c45cb6aa10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64da40b34c3440c592c215c56593aba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Datasets\n",
    "# TODO: this takes a really long time !! why?\n",
    "train_data_tokenized, all_tokens_train = ngram_utils.tokenize_dataset(train_data)\n",
    "valid_data_tokenized, all_tokens_valid = ngram_utils.tokenize_dataset(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23115"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(all_tokens_train))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a great tutu and at a really great price .',\n",
       " \"it doesn ' t look cheap at all .\",\n",
       " \"i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly .\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "for t in train_data_tokenized:\n",
    "    train_data.append(' '.join(t))\n",
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['these are not sized right .',\n",
       " 'a 3x is always big on me and these r cut wrong !',\n",
       " \"i ' m returning them .\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data = []\n",
    "for t in valid_data_tokenized:\n",
    "    valid_data.append(' '.join(t))\n",
    "valid_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107790, 15172)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory where you have the data\n",
    "path = '/home/roberta/ammi-2019-nlp/data/'\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-gram model with KenLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "File stdin isn't normal.  Using slower read() instead of mmap().  No progress bar.\n",
      "Unigram tokens 16393736 types 71696\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:860352 2:75230912512 3:141057966080\n",
      "Statistics:\n",
      "1 71696 D1=0.690098 D2=0.962667 D3+=1.22676\n",
      "2 1239185 D1=0.712943 D2=1.05296 D3+=1.36242\n",
      "3 4834597 D1=0.772513 D2=1.0869 D3+=1.33918\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 113 assuming -p 1.5\n",
      "probing 120 assuming -r models -p 1.5\n",
      "trie     44 without quantization\n",
      "trie     24 assuming -q 8 -b 8 quantization \n",
      "trie     42 assuming -a 22 array pointer compression\n",
      "trie     22 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:860352 2:19826960 3:96691940\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:860352 2:19826960 3:96691940\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:211901448 kB\tVmRSS:27612 kB\tRSSMax:48862532 kB\tuser:14.264\tsys:28.424\tCPU:42.6898\treal:42.4775\n"
     ]
    }
   ],
   "source": [
    "cat train.txt | /home/roberta/kenlm/build/bin/lmplz -o 3 > amazonLM3.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading amazonLM3.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!/home/roberta/kenlm/build/bin/build_binary amazonLM3.arpa amazonLM3.klm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Model from b'amazonLM3.klm'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3n = kenlm.LanguageModel('/home/roberta/ammi-2019-nlp/data/amazonLM3.klm')\n",
    "model_3n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-gram KenLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "File stdin isn't normal.  Using slower read() instead of mmap().  No progress bar.\n",
      "Unigram tokens 16393736 types 71696\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:860352 2:21101352960 3:39565037568 4:63304056832 5:92318425088\n",
      "Statistics:\n",
      "1 71696 D1=0.690098 D2=0.962667 D3+=1.22676\n",
      "2 1239185 D1=0.712943 D2=1.05296 D3+=1.36242\n",
      "3 4834597 D1=0.796199 D2=1.09701 D3+=1.35908\n",
      "4 9215190 D1=0.868874 D2=1.16401 D3+=1.3733\n",
      "5 12376562 D1=0.898907 D2=1.2197 D3+=1.36975\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 564 assuming -p 1.5\n",
      "probing 651 assuming -r models -p 1.5\n",
      "trie    261 without quantization\n",
      "trie    142 assuming -q 8 -b 8 quantization \n",
      "trie    232 assuming -a 22 array pointer compression\n",
      "trie    112 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:860352 2:19826960 3:96691940 4:221164560 5:346543736\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:860352 2:19826960 3:96691940 4:221164560 5:346543736\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:212196376 kB\tVmRSS:27768 kB\tRSSMax:37641320 kB\tuser:37.496\tsys:49.856\tCPU:87.3542\treal:83.9987\n"
     ]
    }
   ],
   "source": [
    "cat train.txt | /home/roberta/kenlm/build/bin/lmplz -o 5 > amazonLM5.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading amazonLM5.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!/home/roberta/kenlm/build/bin/build_binary amazonLM5.arpa amazonLM5.klm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Model from b'amazonLM5.klm'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5n = kenlm.LanguageModel('/home/roberta/ammi-2019-nlp/data/amazonLM5.klm')\n",
    "model_5n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity (Train + Valid Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ov42EMhflktI"
   },
   "source": [
    "### The KenLM model reports negative log likelihood, not perplexity. So we'll be converting the score and report net perplexity. The following function calculate the perpelxity.\n",
    "\n",
    "### Pereplexity is defined as follows, $$ PPL = b^{- \\frac{1}{N} \\sum_{i=1}^N \\log_b q(x_i)} $$ \n",
    "\n",
    "### All probabilities here are in log base 10 so to convert to perplexity, we do the following \n",
    "\n",
    "### $$PPL = 10^{-\\log(P) / N} $$ \n",
    "\n",
    "### where $P$ is the total NLL, and $N$ is the word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLsISNQNlKff"
   },
   "outputs": [],
   "source": [
    "def get_ppl(lm, sentences):\n",
    "    \"\"\"\n",
    "    Assume sentences is a list of strings (space delimited sentences)\n",
    "    \"\"\"\n",
    "    total_nll = 0\n",
    "    total_wc = 0\n",
    "    for sent in sentences:\n",
    "        sent = re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", sent)\n",
    "        words = sent.strip().split()\n",
    "        score = lm.score(sent, bos=False, eos=False)\n",
    "        word_count = len(words)\n",
    "        total_wc += word_count\n",
    "        total_nll += score\n",
    "    ppl = 10**-(total_nll/total_wc)\n",
    "    return ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-gram\n",
    "train_ppl = get_ppl(model_3n, train_data)\n",
    "valid_ppl = get_ppl(model_3n, valid_data)\n",
    "train_ppl, valid_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-gram\n",
    "train_ppl = get_ppl(model_5n, train_data)\n",
    "valid_ppl = get_ppl(model_5n, valid_data)\n",
    "train_ppl, valid_ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['i like this product very much .']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl5 = get_ppl(model_5n, sentences)\n",
    "ppl3, ppl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['i like pandas']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl5 = get_ppl(model_5n, sentences)\n",
    "ppl3, ppl5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4unImHqblPQ9"
   },
   "source": [
    "Function for loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['this color is very ugly']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl5 = get_ppl(model_5n, sentences)\n",
    "ppl3, ppl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['kigali is an awesome city !']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl5 = get_ppl(model_5n, sentences)\n",
    "ppl3, ppl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38.63318152095029, 40.45785877491473)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['i want to get a refund']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl5 = get_ppl(model_5n, sentences)\n",
    "ppl3, ppl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.704919858886626, 28.244409713562888)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['this watch is not what i expected']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl5 = get_ppl(model_5n, sentences)\n",
    "ppl3, ppl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.16364100643393, 28.5398056711585)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['this dress fits me perfectly !']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl5 = get_ppl(model_5n, sentences)\n",
    "ppl3, ppl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53.479550924271464, 79.24041877941873)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['my wife loves this ring']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl5 = get_ppl(model_5n, sentences)\n",
    "ppl3, ppl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppl(lm, sentences):\n",
    "    \"\"\"\n",
    "    Assume sentences is a list of strings (space delimited sentences)\n",
    "    \"\"\"\n",
    "    total_nll = 0\n",
    "    total_wc = 0\n",
    "    for sent in sentences:\n",
    "        sent = re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", sent)\n",
    "        words = sent.strip().split()\n",
    "        score = lm.score(sent, bos=False, eos=False)\n",
    "        word_count = len(words)\n",
    "        total_wc += word_count\n",
    "        total_nll += score\n",
    "    ppl = 10**-(total_nll/total_wc)\n",
    "    return ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['my wife loves this ring']\n",
    "ppl3 = get_ppl(model_3n, sentences)\n",
    "ppl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(lm, context='<s>', max_num_tokens=20):\n",
    "    generated_tokens = []\n",
    "    cur_sent = context\n",
    "    for j in range(max_num_tokens):\n",
    "        scores = []\n",
    "        for i, token in enumerate(vocab):\n",
    "            sent = cur_sent + ' ' + token\n",
    "            if token == '</s>':\n",
    "                eos = True\n",
    "            else:\n",
    "                eos = False\n",
    "            token_score = lm.score(sent, bos=True, eos=eos)\n",
    "            scores.append(token_score)\n",
    "        best_token = vocab[np.argmax(scores)]\n",
    "        generated_tokens.append(best_token)\n",
    "        cur_sent = cur_sent + ' ' + best_token\n",
    "        if best_token == '</s>':\n",
    "            break\n",
    "    return generated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(8)generate()\n",
      "-> sent = cur_sent + ' ' + token\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  best_token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'i'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  best_token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bought'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  cur_sentence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'cur_sentence' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  cur_sent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s> i bought'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  best_token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'my'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  generated_tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'bought', 'this', 'for', 'my', 'husband']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  \n",
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  generated_tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'bought', 'this', 'for', 'my', 'husband', 'and', 'he', 'loves', 'them', '.', 'i', \"'\", 'm', 'not']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(6)generate()\n",
      "-> import pdb; pdb.set_trace()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-16-e127432e825d>(7)generate()\n",
      "-> for i, token in enumerate(vocab):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  generated_tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'bought', 'this', 'for', 'my', 'husband', 'and', 'he', 'loves', 'them', '.', 'i', \"'\", 'm', 'not', 'sure', 'if', 'i', 'had']\n"
     ]
    }
   ],
   "source": [
    "s3 = generate(model_3n)\n",
    "s5 = generate(model_5n)\n",
    "s3, s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '<s> i'\n",
    "s3 = generate(model_3n, context=context)\n",
    "s5 = generate(model_5n, context=context)\n",
    "s3, s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '<s> i like'\n",
    "s3 = generate(model_3n, context=context)\n",
    "s5 = generate(model_5n, context=context)\n",
    "s3, s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '<s> i am'\n",
    "s3 = generate(model_3n, context=context)\n",
    "s5 = generate(model_5n, context=context)\n",
    "s3, s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '<s> this'\n",
    "s3 = generate(model_3n, context=context)\n",
    "s5 = generate(model_5n, context=context)\n",
    "s3, s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '<s> this dress'\n",
    "s3 = generate(model_3n, context=context)\n",
    "s5 = generate(model_5n, context=context)\n",
    "s3, s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '<s> this animal'\n",
    "s3 = generate(model_3n, context=context)\n",
    "s5 = generate(model_5n, context=context)\n",
    "s3, s5"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ken_lm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
