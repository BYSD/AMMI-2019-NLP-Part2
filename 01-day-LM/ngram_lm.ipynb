{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyunghyuncho/ammi-2019-nlp/blob/master/01-day-LM/ngram_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "### Goal: compute a probabilty distribution over all possible sentences:\n",
    "\n",
    "\n",
    "### $$p(W) = p(w_1, w_2, ..., w_T)$$\n",
    "\n",
    "### This unsupervised learning problem can be framed as a sequence of supervised learning problems:\n",
    "\n",
    "### $$p(W) = p(w_1) * p(w_2|w_1) * ... * p(w_T|w_1, ..., w_{T-1})$$\n",
    "\n",
    "### If we have K sentences, where the j-th sentence has T_j words for all j frmo 1 to K, then we want to max:\n",
    "\n",
    "### $$log p(W) = \\sum_{j = 1}^K \\sum_{i=1}^{T_j} log p(w_i | w_{<i})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram language model\n",
    "\n",
    "### Goal: estimate the n-gram probabilities using counts of sequences of n consecutive words\n",
    "\n",
    "### Given a sequence of words $w$, we want to compute\n",
    "\n",
    "###  $$P(w_i|w_{i−1}, w_{i−2}, …, w_{i−n+1})$$\n",
    "\n",
    "### Where $w_i$ is the i-th word of the sequence.\n",
    "\n",
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) = \\frac{p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} p(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n",
    "\n",
    "### Key Idea: We can estimate the probabilities using counts of n-grams in our dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Probabilities\n",
    "\n",
    "## $$p(w_i | w_{i-1}) = \\frac{c(w_{i-1}, w_i)}{\\sum_{w_i} c(w_{i-1}, w_i)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Processing\n",
    "### 2. Ngram Counts and Probabilities\n",
    "### 3. Trie Implementation\n",
    "### 4. Smoothing\n",
    "### 5. Perplexity\n",
    "### 6. Sentence Score\n",
    "### 7. Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('utils/')\n",
    "from utils import ngram_utils as ngram_utils\n",
    "import utils.global_variables as gl\n",
    "import torch\n",
    "import random\n",
    "from utils.ngram_utils import NgramLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H20pktPiA63a",
    "outputId": "fb38d897-e889-4451-df77-9ca98eb266a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f420ca388f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from .txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .txt files and create lists of reviews\n",
    "\n",
    "train_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_train.txt', 'r') as f:\n",
    "    train_data = [review for review in f.read().split('\\n') if review]\n",
    "    \n",
    "valid_data = []\n",
    "# create a list of all the reviews \n",
    "with open('../data/amazon_valid.txt', 'r') as f:\n",
    "    valid_data = [review for review in f.read().split('\\n') if review]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_data), len(train_data), \\\n",
    "# type(train_data[0]), len(train_data[0]), \\\n",
    "# type(train_data[0][0]), len(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this is a great tutu and at a really great price . it doesn ' t look cheap at all . i ' m so glad i looked on amazon and found such an affordable tutu that isn ' t made poorly . a + + \",\n",
       " 't',\n",
       " 22288)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_data[0][0], len(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b986f132404bfb9405bd1938f09a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b2344192d141d6bbbd1d12bbe91be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Datasets\n",
    "# TODO: this takes a really long time !! why?\n",
    "train_data_tokenized, all_tokens_train = ngram_utils.tokenize_dataset(train_data)\n",
    "valid_data_tokenized, all_tokens_valid = ngram_utils.tokenize_dataset(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the tokenized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107790,\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'tutu',\n",
       "  'and',\n",
       "  'at',\n",
       "  'a',\n",
       "  'really',\n",
       "  'great',\n",
       "  'price',\n",
       "  '.'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Number of All Tokens\n",
    "# len(all_tokens_train), all_tokens_train[0], \\\n",
    "len(train_data_tokenized), train_data_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram_lm = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing=None)\n",
    "valid_ngram_lm = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96175"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_lm.trie_ngram['./<eos>/<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_lm.n, train_ngram_lm.frac_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<sos>', '<eos>', '.', 'the', 'i', ',', 'and', 'a', 'it']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.id2token[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.token2id['<unk>'], valid_ngram_lm.token2id['<sos>'], valid_ngram_lm.token2id['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', '<sos>', 'the'),\n",
       "  ('<sos>', '<sos>', 'it'),\n",
       "  ('!', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'this'),\n",
       "  ('it', \"'\", 's'),\n",
       "  ('.', '.', '.'),\n",
       "  ('.', '.', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'they')),\n",
       " (13625, 3635, 1425, 1100, 1049, 762, 687, 655, 580, 569))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_ngram[:10], valid_ngram_lm.count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>'),\n",
       "  ('<sos>', 'i'),\n",
       "  ('<sos>', 'the'),\n",
       "  (\"'\", 't'),\n",
       "  (\"'\", 's'),\n",
       "  ('.', '.'),\n",
       "  ('<sos>', 'it'),\n",
       "  ('!', '<eos>'),\n",
       "  (',', 'and'),\n",
       "  (',', 'but')),\n",
       " (13625, 3635, 1425, 1261, 1249, 1238, 1100, 1049, 900, 838))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_bigram[:10], valid_ngram_lm.count_bigram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.',),\n",
       "  ('the',),\n",
       "  ('i',),\n",
       "  (',',),\n",
       "  ('and',),\n",
       "  ('a',),\n",
       "  ('it',),\n",
       "  ('to',),\n",
       "  (\"'\",),\n",
       "  ('is',)),\n",
       " (14883, 9408, 8000, 7525, 6226, 5774, 5085, 4550, 3816, 3695))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_unigram[:10], valid_ngram_lm.count_unigram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>'),\n",
       "  ('<sos>', 'i'),\n",
       "  ('<sos>', 'the'),\n",
       "  (\"'\", 't'),\n",
       "  (\"'\", 's'),\n",
       "  ('.', '.'),\n",
       "  ('<sos>', 'it'),\n",
       "  ('!', '<eos>'),\n",
       "  (',', 'and'),\n",
       "  (',', 'but')),\n",
       " (13625, 3635, 1425, 1261, 1249, 1238, 1100, 1049, 900, 838))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.vocab_prev_ngram[:10], valid_ngram_lm.count_prev_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', '<eos>', '<eos>'),\n",
       " ('<sos>', '<sos>', 'i'),\n",
       " ('<sos>', '<sos>', 'the'),\n",
       " ('<sos>', '<sos>', 'it'),\n",
       " ('!', '<eos>', '<eos>'),\n",
       " ('<sos>', '<sos>', 'this'),\n",
       " ('it', \"'\", 's'),\n",
       " ('.', '.', '.'),\n",
       " ('.', '.', '<eos>'),\n",
       " ('<sos>', '<sos>', 'they')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.id2token_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ngram_lm.token2id_ngram[('.', '<eos>', '<eos>')], valid_ngram_lm.token2id_ngram[('.', '.', '<eos>')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the Vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocabulary size: 20806 words\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary using all the tokens found in train data (90% of most common ones)\n",
    "print('Word vocabulary size: {} words'.format(len(train_ngram_lm.token2id)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORPUS ANALYSIS (Train + Valid Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tokens in the Corpus Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Tokens  1623446\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of All Tokens \", len(all_tokens_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Sentences in the Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences  107790\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Sentences \", len(train_ngram_lm.raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for padding the sentences with special markers sentence beginning and end, i.e. $<bos>$ and $<eos>$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = train_ngram_lm.padded_data\n",
    "train_ngram = train_ngram_lm.ngram_data\n",
    "vocab_ngram = train_ngram_lm.vocab_ngram\n",
    "count_ngram = train_ngram_lm.count_ngram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '<sos>',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'great',\n",
       " 'tutu',\n",
       " 'and',\n",
       " 'at',\n",
       " 'a',\n",
       " 'really',\n",
       " 'great',\n",
       " 'price',\n",
       " '.',\n",
       " '<eos>',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for finding all N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<sos>', '<sos>', 'this'),\n",
       " ('<sos>', 'this', 'is'),\n",
       " ('this', 'is', 'a'),\n",
       " ('is', 'a', 'great'),\n",
       " ('a', 'great', 'tutu'),\n",
       " ('great', 'tutu', 'and'),\n",
       " ('tutu', 'and', 'at'),\n",
       " ('and', 'at', 'a'),\n",
       " ('at', 'a', 'really'),\n",
       " ('a', 'really', 'great'),\n",
       " ('really', 'great', 'price'),\n",
       " ('great', 'price', '.'),\n",
       " ('price', '.', '<eos>'),\n",
       " ('.', '<eos>', '<eos>')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.', '<eos>', '<eos>')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96175"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_ngram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie_ngram = train_ngram_lm.trie_ngram\n",
    "# trie_ngram\n",
    "# trie_prev_ngram = train_ngram_lm.trie_prev_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96175"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie_ngram['./<eos>/<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token = train_ngram_lm.id2token\n",
    "token2id = train_ngram_lm.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token_ngram = train_ngram_lm.id2token_ngram\n",
    "token2id_ngram = train_ngram_lm.token2id_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 574532 ; token ('58', 'mm', 'which')\n",
      "Token ('58', 'mm', 'which'); token id 574532\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token_ngram) - 1)\n",
    "random_token = id2token_ngram[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token_ngram[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id_ngram[random_token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Count & Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the words for which the pd is nonzero !!! -- more intuitive than a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((('.', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', '<sos>', 'the'),\n",
       "  ('!', '<eos>', '<eos>'),\n",
       "  ('<sos>', '<sos>', 'they'),\n",
       "  ('<sos>', '<sos>', 'it'),\n",
       "  ('.', '.', '.'),\n",
       "  ('<sos>', '<sos>', 'this'),\n",
       "  ('<sos>', '<sos>', 'these'),\n",
       "  ('.', '.', '<eos>')),\n",
       " (96175, 26986, 9197, 8152, 6376, 5373, 4693, 4189, 3941, 3876))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ngram[:10], count_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 0.041666666666666664,\n",
       " 0.041666666666666664,\n",
       " 0.041666666666666664,\n",
       " 0.0,\n",
       " 0.9999999999999999)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('an', 'older', 'coat'))\n",
    "p = train_ngram_lm.get_ngram_prob(('an', 'older', 'coat'))\n",
    "\n",
    "p1 = train_ngram_lm.get_ngram_prob(('an', 'older', 'pc'))\n",
    "p2 = train_ngram_lm.get_ngram_prob(('an', 'older', 'lady'))\n",
    "p3 = train_ngram_lm.get_ngram_prob(('an', 'older', 'watch'))\n",
    "\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('an', 'older'))\n",
    "\n",
    "c, p, p1, p2, p3, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.061224489795918366, 0.9999999999999997)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('really', 'great', 'price'))\n",
    "p = train_ngram_lm.get_ngram_prob(('really', 'great', 'price'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('really', 'great'))\n",
    "\n",
    "c, p, sum(pd)#, pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('really', 'great'))\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96175, 1.0, 1.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('.', '<eos>', '<eos>'))\n",
    "p = train_ngram_lm.get_ngram_prob(('.', '<eos>', '<eos>'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('.', '<eos>'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('.', '<sos>', '<sos>'))\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0.9999999999999994)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "p = train_ngram_lm.get_ngram_count(('i', 'like', 'pandas'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 0.09819121447028424, 0.9999999999999787)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('is', 'a', 'great'))\n",
    "p = train_ngram_lm.get_ngram_prob(('is', 'a', 'great'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('is', 'a'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 0.9032258064516129, 1.0000000000000657)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('send', 'it', 'back'))\n",
    "p = train_ngram_lm.get_ngram_prob(('send', 'it', 'back'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('send', 'it', 'back'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 1.0000000000000657)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_ngram_lm.get_ngram_count(('i', 'like', 'these', 'pictures'))\n",
    "p = train_ngram_lm.get_ngram_prob(('i', 'like', 'these', 'pictures'))\n",
    "pd = train_ngram_lm.get_prob_distr_ngram(('i', 'like', 'these'))\n",
    "\n",
    "c, p, sum(pd)#, pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-One Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{1 + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.806305873305777e-05"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<sos>', '<sos>'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.504910352283989e-05"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'pandas'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00432471393819263"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('i', 'like', 'this'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001918005274514505"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('really', 'great', 'price'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013917550511110045"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('send', 'it', 'back'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8221506056539096"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_add_one_smoothing(('.', '<eos>', '<eos>'))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\frac{\\delta + c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w_i)}{\\delta\\mid V\\mid + \\sum_{w \\in V} c(w_{i−n+1}, ..., w_{i−2}, w_{i−1}, w)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.806305873305777e-05"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<sos>', '<sos>'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.23908435777872e-05"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'pandas'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008096651123357355"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('i', 'like', 'this'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00033486414083429007"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('really', 'great', 'price'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027314548591144336"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('send', 'it', 'back'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9023954287001069"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Parameter $\\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788256343658784"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370371208455323"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arge delta --> closer to add-one smoothing (0.58)\n",
    "p = train_ngram_lm.get_ngram_prob_additive_smoothing(('.', '<eos>', '<eos>'), delta = 0.9)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation Smoothing (Jelinek-Mercer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) \\approx \\alpha_n P(w_i|w_{i−n+1}, ..., w_{i−2}, w_{i−1}) + (1 - \\alpha_n) P(w|w_{i−n+2}, ..., w_{i−2}, w_{i−1})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<sos>', '<sos>'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'pandas'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0545977011494253"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('i', 'like', 'this'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0489795918367347"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('really', 'great', 'price'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7225806451612904"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('send', 'it', 'back'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Parameter $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.8)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.5)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small delta --> closer to no smoothing  (1.0)\n",
    "p = train_ngram_lm.get_ngram_prob_interpolation_smoothing(('.', '<eos>', '<eos>'), alpha = 0.2)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Interpolation with Absolute Discounting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$p_{bi}(w|v) = max ({ \\frac{N(v, w) - b_{bi}}{N(v)}, 0)  + b_{bi} \\frac{V - N_0(v, \\cdot)}{N(v)} p_{uni}(w) \\large}$$\n",
    "\n",
    "### $$p_{uni}(w) = max ({ \\frac{N(w) - b_{uni}}{N}, 0)  + b_{uni} \\frac{V - N_0(\\cdot)}{N} \\frac{1}{V}}$$\n",
    "\n",
    "### $$b_{bi} = \\frac{N_1(\\cdot, \\cdot)}{N_1(\\cdot, \\cdot) + 2*N_2(\\cdot, \\cdot)}$$\n",
    "\n",
    "### $$b_{uni} = \\frac{N_1(\\cdot)}{N_1(\\cdot) + 2*N_2(\\cdot)}$$\n",
    "\n",
    "\n",
    "### $$N_r(\\cdot) = \\sum_{w: N(w) = r} 1$$\n",
    "\n",
    "### $$N_r(\\cdot, \\cdot) = \\sum_{v, w: N(v, w) = r} 1$$\n",
    "\n",
    "### $$N_r(v, \\cdot) = \\sum_{w: N(v, w) = r} 1$$\n",
    "\n",
    "### V is the number of words in the vocabulary\n",
    "\n",
    "### $N_r(\\cdot, \\cdot)$ and $N_r(\\cdot)$  are the count-counts for bigrams and unigrams respectively $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to check that probabilities sum up to one:\n",
    "### $$\\sum_w p_{bi}(w|v) = \\sum_w p_{uni}(w) = 1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = \"m\"\n",
    "# x = \"'\"\n",
    "\n",
    "# z = train_ngram_lm.get_p_bi(y, x)\n",
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('<sos>', '<sos>', 'this'),\n",
       "  ('<sos>', 'this', 'is'),\n",
       "  ('this', 'is', 'a'),\n",
       "  ('is', 'a', 'great'),\n",
       "  ('a', 'great', 'tutu'),\n",
       "  ('great', 'tutu', 'and'),\n",
       "  ('tutu', 'and', 'at'),\n",
       "  ('and', 'at', 'a'),\n",
       "  ('at', 'a', 'really'),\n",
       "  ('a', 'really', 'great'),\n",
       "  ('really', 'great', 'price'),\n",
       "  ('great', 'price', '.'),\n",
       "  ('price', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')],\n",
       " [('<sos>', '<sos>', 'it'),\n",
       "  ('<sos>', 'it', 'doesn'),\n",
       "  ('it', 'doesn', \"'\"),\n",
       "  ('doesn', \"'\", 't'),\n",
       "  (\"'\", 't', 'look'),\n",
       "  ('t', 'look', 'cheap'),\n",
       "  ('look', 'cheap', 'at'),\n",
       "  ('cheap', 'at', 'all'),\n",
       "  ('at', 'all', '.'),\n",
       "  ('all', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')],\n",
       " [('<sos>', '<sos>', 'i'),\n",
       "  ('<sos>', 'i', \"'\"),\n",
       "  ('i', \"'\", 'm'),\n",
       "  (\"'\", 'm', 'so'),\n",
       "  ('m', 'so', 'glad'),\n",
       "  ('so', 'glad', 'i'),\n",
       "  ('glad', 'i', 'looked'),\n",
       "  ('i', 'looked', 'on'),\n",
       "  ('looked', 'on', 'amazon'),\n",
       "  ('on', 'amazon', 'and'),\n",
       "  ('amazon', 'and', 'found'),\n",
       "  ('and', 'found', 'such'),\n",
       "  ('found', 'such', 'an'),\n",
       "  ('such', 'an', 'affordable'),\n",
       "  ('an', 'affordable', 'tutu'),\n",
       "  ('affordable', 'tutu', 'that'),\n",
       "  ('tutu', 'that', 'isn'),\n",
       "  ('that', 'isn', \"'\"),\n",
       "  ('isn', \"'\", 't'),\n",
       "  (\"'\", 't', 'made'),\n",
       "  ('t', 'made', 'poorly'),\n",
       "  ('made', 'poorly', '.'),\n",
       "  ('poorly', '.', '<eos>'),\n",
       "  ('.', '<eos>', '<eos>')]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney Smoothing (best to use in practice!) http://smithamilli.com/blog/kneser-ney/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM\n",
    "###  $$p(s) = \\prod_{i = 1} ^ {N + 1} p(w_i | w_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood of a Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram LM: $$ p(i \\; love \\; this \\; light) = p(i|\\cdot) \\; p(love|i)\\;  p(this|love)\\;  p(light|this) \\\\\n",
    "\\approx \\frac{c(i, \\cdot)}{\\sum_w c(\\cdot, \\; w)} \\; \\frac{c(love, i)}{\\sum_wc(i, \\; w)}\\;  \\frac{c(this, love)}{\\sum_wc(love, \\;w)}\\;  \\frac{c(light, this)}{\\sum_wc(this, \\;w)}$$ \n",
    "\n",
    "### Trigram LM: $$ p(i \\; love \\; this  \\;light) = p(i|\\cdot, \\cdot) \\; p(love|\\cdot, i) \\; p(this|i, love)\\;  p(light|love, this)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 5.126374389946876e+77)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ss =  train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.0043653926145575e-13, 6.706528173768987)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i think\n",
      "i think they\n",
      "i think they can\n",
      "i think they can be\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i think they can be'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones\n",
      "ones here\n",
      "ones here ,\n",
      "ones here , let\n",
      "ones here , let '\n",
      "ones here , let ' s\n",
      "ones here , let ' s well\n",
      "ones here , let ' s well constructed\n",
      "ones here , let ' s well constructed and\n",
      "ones here , let ' s well constructed and fit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"ones here , let ' s well constructed and fit\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on\n",
      "on this\n",
      "on this product\n",
      "on this product and\n",
      "on this product and the\n",
      "on this product and the second\n",
      "on this product and the second bag\n",
      "on this product and the second bag in\n",
      "on this product and the second bag in a\n",
      "on this product and the second bag in a store\n",
      "on this product and the second bag in a store .\n",
      "on this product and the second bag in a store . <eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'on this product and the second bag in a store . <eos>'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact\n",
      "fact that\n",
      "fact that now\n",
      "fact that now .\n",
      "fact that now . <eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fact that now . <eos>'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moss\n",
      "moss color\n",
      "moss color so\n",
      "moss color so i\n",
      "moss color so i went\n",
      "moss color so i went back\n",
      "moss color so i went back and\n",
      "moss color so i went back and helps\n",
      "moss color so i went back and helps you\n",
      "moss color so i went back and helps you !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'moss color so i went back and helps you !'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color\n",
      "color and\n",
      "color and style\n",
      "color and style .\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'like', 'the'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('the', 'worst'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('the', 'best'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('not', 'what'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 5\n",
    "generated_sentence = train_ngram_lm.generate_sentence(num_tokens, context=('i', 'will'))\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Likelihood (n-gram)\n",
    "## $$LL = \\sum_{j=1}^{K} \\sum_{i=1}^{T_j + 1} log p_{bi}(w_{j, i} | w_{j, n - i + 1}, \\cdot, w_{j, i - 2}, w_{j, i - 1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity\n",
    "## $$PP = exp(-\\frac{LL}{\\sum_j(T_j + 1)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_train = train_ngram_lm.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid = train_ngram_lm.get_perplexity(valid_data_tokenized, subsample=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_valid, ppl_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation Smoothing - varying N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 2\n",
    "train_ngram_lm_interp2 = NgramLM(train_data_tokenized, all_tokens_train, n=2, smoothing='interpolation')\n",
    "valid_ngram_lm_interp2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=2, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp2 = train_ngram_lm_interp2.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp2 = train_ngram_lm_interp2.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp2, ppl_train_no_interp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 3\n",
    "train_ngram_lm_interp3 = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='interpolation')\n",
    "valid_ngram_lm_interp3 = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp3 = train_ngram_lm_interp3.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp3 = train_ngram_lm_interp3.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp3, ppl_train_no_interp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 5\n",
    "train_ngram_lm_interp5 = NgramLM(train_data_tokenized, all_tokens_train, n=5, smoothing='interpolation')\n",
    "valid_ngram_lm_interp5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=5, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp5 = train_ngram_lm_interp5.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp5 = train_ngram_lm_interp5.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp5, ppl_train_no_interp5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 7\n",
    "train_ngram_lm_interp7 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation')\n",
    "valid_ngram_lm_interp7 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp7 = train_ngram_lm_interp7.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp7 = train_ngram_lm_interp7.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp7, ppl_train_no_interp7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing, N = 10\n",
    "train_ngram_lm_interp10 = NgramLM(train_data_tokenized, all_tokens_train, n=10, smoothing='interpolation')\n",
    "valid_ngram_lm_interp10 = NgramLM(valid_data_tokenized, all_tokens_valid, n=10, smoothing='interpolation')\n",
    "\n",
    "ppl_train_no_interp10 = train_ngram_lm_interp10.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp10 = train_ngram_lm_interp10.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp10, ppl_train_no_interp10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Compare Different Smoothing Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Smoothing\n",
    "train_ngram_lm_no_smoothing = NgramLM(train_data_tokenized, all_tokens_train, n=7)\n",
    "valid_ngram_lm_no_smoothing = NgramLM(valid_data_tokenized, all_tokens_valid, n=7)\n",
    "\n",
    "ppl_train_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_smoothing = train_ngram_lm_no_smoothing.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_smoothing, ppl_train_no_smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.5)\n",
    "valid_ngram_lm_additive = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.5)\n",
    "\n",
    "ppl_train_no_additive = train_ngram_lm_additive.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_additive = train_ngram_lm_additive.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_additive, ppl_train_no_additive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive_d2 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.2)\n",
    "valid_ngram_lm_additive_d2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.2)\n",
    "\n",
    "ppl_train_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_additive_d2 = train_ngram_lm_additive_d2.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_additive_d2, ppl_train_no_additive_d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_additive_d8 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='additive', delta=0.8)\n",
    "valid_ngram_lm_additive_d8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='additive', delta=0.8)\n",
    "\n",
    "ppl_train_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_additive_d8 = train_ngram_lm_additive_d8.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_additive_d8, ppl_train_no_additive_d8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive Smoothing\n",
    "train_ngram_lm_add1 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='add-one')\n",
    "valid_ngram_lm_add1 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='add-one')\n",
    "\n",
    "ppl_train_no_add1 = train_ngram_lm_add1.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_add1 = train_ngram_lm_add1.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_add1, ppl_train_no_add1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a2 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.2)\n",
    "valid_ngram_lm_interp_a2 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.2)\n",
    "\n",
    "ppl_train_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp_a2 = train_ngram_lm_interp_a2.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp_a2, ppl_train_no_interp_a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a8 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.8)\n",
    "valid_ngram_lm_interp_a8 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.8)\n",
    "\n",
    "ppl_train_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp_a8 = train_ngram_lm_interp_a8.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp_a8, ppl_train_no_interp_a8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation Smoothing\n",
    "train_ngram_lm_interp_a5 = NgramLM(train_data_tokenized, all_tokens_train, n=7, smoothing='interpolation', alpha=0.5)\n",
    "valid_ngram_lm_interp_a5 = NgramLM(valid_data_tokenized, all_tokens_valid, n=7, smoothing='interpolation', alpha=0.5)\n",
    "\n",
    "ppl_train_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(train_data_tokenized, subsample=10)\n",
    "ppl_valid_no_interp_a5 = train_ngram_lm_interp_a5.get_perplexity(valid_data_tokenized, subsample=10)\n",
    "\n",
    "ppl_valid_no_interp_a5, ppl_train_no_interp_a5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Discounted Interpolation Smoothing\n",
    "# train_ngram_lm_discount = NgramLM(train_data_tokenized, all_tokens_train, n=3, smoothing='discounting')\n",
    "# valid_ngram_lm_discount = NgramLM(valid_data_tokenized, all_tokens_valid, n=3, smoothing='discounting')\n",
    "\n",
    "# ppl_train_no_discount = train_ngram_lm_discount.get_perplexity(train_data_tokenized)\n",
    "# ppl_valid_no_discount = train_ngram_lm_discount.get_perplexity(valid_data_tokenized)\n",
    "\n",
    "# ppl_valid_no_discount, ppl_train_no_discount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive Smoothing - varying N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp3.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_interp3.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp5.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_interp5.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp7.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_interp7.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_interp10.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_interp10.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['this', 'is', 'a', 'great', 'tutu', 'and', 'at', 'a', 'really', 'great', 'price', '.']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['i', 'like', 'pandas']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['i really like this watch']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [['my wife really likes the color of this dress']]\n",
    "print(sentence)\n",
    "ps = train_ngram_lm_additive.get_prob_sentence(sentence)\n",
    "ss = train_ngram_lm_additive.get_score_sentence(sentence)\n",
    "ps, ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp3.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp5.generate_sentence(num_tokens)\n",
    "generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp7.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 20\n",
    "generated_sentence = train_ngram_lm_interp10.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_additive.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 10\n",
    "generated_sentence = train_ngram_lm_no_smoothing.generate_sentence(num_tokens)\n",
    "generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ngram-lm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
